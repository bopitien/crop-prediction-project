{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342f2e1f",
   "metadata": {},
   "source": [
    "The task in your project involves two main objectives:\n",
    "\n",
    "Predict the Crop Type: Use the variables \n",
    "ùëÅ\n",
    "N (Nitrogen), \n",
    "ùëÉ\n",
    "P (Phosphorous), \n",
    "ùêæ\n",
    "K (Potassium), and pH value of the soil to build a machine learning model that can predict the type of crop (categorical target variable) that would be best suited for a given set of soil conditions. This is a classic example of a multi-class classification problem.\n",
    "\n",
    "Identify the Most Significant Variable: Apart from predicting the crop type, a key part of your project is to determine which of these soil metrics (N, P, K, or pH) is the most predictive of the crop type. This involves analyzing the feature importance from your model to see which variable contributes the most to the model's predictive performance. This helps in understanding which soil metric is most critical for deciding the crop type, which can be very valuable for optimizing the use of resources in agricultural practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f904f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2bd0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "crops = pd.read_csv(\"soil_measures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f40909f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>ph</th>\n",
       "      <th>crop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>7.073454</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>5.700806</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>5.718627</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>54</td>\n",
       "      <td>38</td>\n",
       "      <td>6.685346</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>58</td>\n",
       "      <td>38</td>\n",
       "      <td>6.336254</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N   P   K        ph  crop\n",
       "0  90  42  43  6.502985  rice\n",
       "1  85  58  41  7.038096  rice\n",
       "2  60  55  44  7.840207  rice\n",
       "3  74  35  40  6.980401  rice\n",
       "4  78  42  42  7.628473  rice\n",
       "5  69  37  42  7.073454  rice\n",
       "6  69  55  38  5.700806  rice\n",
       "7  94  53  40  5.718627  rice\n",
       "8  89  54  38  6.685346  rice\n",
       "9  68  58  38  6.336254  rice"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9c079c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N         int64\n",
       "P         int64\n",
       "K         int64\n",
       "ph      float64\n",
       "crop     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "612c97ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       0\n",
       "P       0\n",
       "K       0\n",
       "ph      0\n",
       "crop    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50961a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>ph</th>\n",
       "      <th>crop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.551818</td>\n",
       "      <td>53.362727</td>\n",
       "      <td>48.149091</td>\n",
       "      <td>6.469480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.917334</td>\n",
       "      <td>32.985883</td>\n",
       "      <td>50.647931</td>\n",
       "      <td>0.773938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.504752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.971693</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.425045</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>84.250000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>6.923643</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>9.935091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  N            P            K           ph  crop\n",
       "count   2200.000000  2200.000000  2200.000000  2200.000000  2200\n",
       "unique          NaN          NaN          NaN          NaN    22\n",
       "top             NaN          NaN          NaN          NaN  rice\n",
       "freq            NaN          NaN          NaN          NaN   100\n",
       "mean      50.551818    53.362727    48.149091     6.469480   NaN\n",
       "std       36.917334    32.985883    50.647931     0.773938   NaN\n",
       "min        0.000000     5.000000     5.000000     3.504752   NaN\n",
       "25%       21.000000    28.000000    20.000000     5.971693   NaN\n",
       "50%       37.000000    51.000000    32.000000     6.425045   NaN\n",
       "75%       84.250000    68.000000    49.000000     6.923643   NaN\n",
       "max      140.000000   145.000000   205.000000     9.935091   NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7505c6ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rice', 'maize', 'chickpea', 'kidneybeans', 'pigeonpeas',\n",
       "       'mothbeans', 'mungbean', 'blackgram', 'lentil', 'pomegranate',\n",
       "       'banana', 'mango', 'grapes', 'watermelon', 'muskmelon', 'apple',\n",
       "       'orange', 'papaya', 'coconut', 'cotton', 'jute', 'coffee'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops[\"crop\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8c657",
   "metadata": {},
   "source": [
    "# A. Predict the Crop Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf783b6",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01b03772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = crops[['N', 'P', 'K', 'ph']] \n",
    "y = crops['crop']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the training data and transform the test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47e78758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92cb35e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6590909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.88      0.30      0.45        23\n",
      "      banana       1.00      1.00      1.00        21\n",
      "   blackgram       0.76      0.65      0.70        20\n",
      "    chickpea       1.00      0.77      0.87        26\n",
      "     coconut       0.81      0.63      0.71        27\n",
      "      coffee       0.76      0.76      0.76        17\n",
      "      cotton       0.88      0.88      0.88        17\n",
      "      grapes       0.45      0.93      0.60        14\n",
      "        jute       0.50      0.48      0.49        23\n",
      " kidneybeans       0.45      0.65      0.53        20\n",
      "      lentil       0.30      0.64      0.41        11\n",
      "       maize       0.91      1.00      0.95        21\n",
      "       mango       0.40      0.53      0.45        19\n",
      "   mothbeans       0.60      0.25      0.35        24\n",
      "    mungbean       0.67      0.74      0.70        19\n",
      "   muskmelon       0.62      0.76      0.68        17\n",
      "      orange       1.00      1.00      1.00        14\n",
      "      papaya       0.74      1.00      0.85        23\n",
      "  pigeonpeas       0.18      0.09      0.12        23\n",
      " pomegranate       0.69      0.87      0.77        23\n",
      "        rice       0.38      0.32      0.34        19\n",
      "  watermelon       0.73      0.58      0.65        19\n",
      "\n",
      "    accuracy                           0.66       440\n",
      "   macro avg       0.67      0.67      0.65       440\n",
      "weighted avg       0.68      0.66      0.65       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict the crop types on the scaled test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb885d",
   "metadata": {},
   "source": [
    "### Implementation Steps:\n",
    "* Data Preparation: Features and labels are defined, data is split into training and testing sets.\n",
    "* Feature Scaling: StandardScaler is used to scale the features, which is crucial for logistic regression as it relies on gradient descent algorithms that benefit from feature scaling.\n",
    "* Model Training and Prediction: A logistic regression model is initialized and trained on the scaled data. Predictions are then made on the test set.\n",
    "* Evaluation: The model's performance is assessed using accuracy and a detailed classification report which provides precision, recall, and F1-scores for each class.\n",
    "\n",
    "### Outcomes:\n",
    "* Overall Accuracy: 65.91%, indicating that the model correctly predicts the crop type for about two-thirds of the test set.\n",
    "* Performance Variability: The model performs well for certain crops like banana and chickpea but struggles with others like pigeonpeas and rice, suggesting variability in its ability to handle different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f83c117",
   "metadata": {},
   "source": [
    "### 2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b330595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Accuracy: 0.8227272727272728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.78      0.61      0.68        23\n",
      "      banana       1.00      1.00      1.00        21\n",
      "   blackgram       0.85      0.85      0.85        20\n",
      "    chickpea       1.00      1.00      1.00        26\n",
      "     coconut       0.84      0.96      0.90        27\n",
      "      coffee       0.94      0.94      0.94        17\n",
      "      cotton       0.89      1.00      0.94        17\n",
      "      grapes       0.53      0.71      0.61        14\n",
      "        jute       0.55      0.78      0.64        23\n",
      " kidneybeans       0.77      1.00      0.87        20\n",
      "      lentil       0.47      0.73      0.57        11\n",
      "       maize       1.00      0.95      0.98        21\n",
      "       mango       0.93      0.74      0.82        19\n",
      "   mothbeans       0.95      0.88      0.91        24\n",
      "    mungbean       0.76      1.00      0.86        19\n",
      "   muskmelon       0.65      0.65      0.65        17\n",
      "      orange       1.00      1.00      1.00        14\n",
      "      papaya       1.00      1.00      1.00        23\n",
      "  pigeonpeas       1.00      0.39      0.56        23\n",
      " pomegranate       1.00      0.91      0.95        23\n",
      "        rice       0.50      0.21      0.30        19\n",
      "  watermelon       0.68      0.68      0.68        19\n",
      "\n",
      "    accuracy                           0.82       440\n",
      "   macro avg       0.82      0.82      0.81       440\n",
      "weighted avg       0.84      0.82      0.82       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30],        # Maximum number of levels in each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='f1_macro')\n",
    "\n",
    "# Fit grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f6533f",
   "metadata": {},
   "source": [
    "### Implementation Steps:\n",
    "\n",
    "* Model Setup: Random Forest Classifier is defined.\n",
    "\n",
    "* Hyperparameter Tuning: GridSearchCV is utilized to find the optimal parameters (like the number of trees, maximum depth of trees, etc.) across a specified grid. This helps in optimizing the model by tuning it to the best possible configuration for the given data.\n",
    "\n",
    "* Model Training and Prediction: The best model from GridSearchCV is used to make predictions on the test set.\n",
    "\n",
    "* Evaluation: Similar to logistic regression, the model‚Äôs performance is evaluated using accuracy and a detailed classification report.\n",
    "\n",
    "#### Outcomes:\n",
    "* Overall Accuracy: 82.27%, a significant improvement over the logistic regression model.\n",
    "\n",
    "* Enhanced Performance: The Random Forest model shows not only higher overall accuracy but also improved precision, recall, and F1-scores for most crops. This indicates a better handling of class variability and an overall stronger predictive performance.\n",
    "\n",
    "### Rationale Behind Method Selection\n",
    "* Logistic Regression: A good baseline model for classification tasks. It's relatively simple and interpretable but may not handle complex relationships and interactions between features as effectively, especially in multi-class settings.\n",
    "\n",
    "* Random Forest: An ensemble method that builds multiple decision trees and aggregates their predictions. It's more robust against overfitting and can capture complex patterns in the data, making it suitable for tasks with high-dimensional feature space and multiple classes.\n",
    "\n",
    "### Interpretation and Recommendations\n",
    "The significant improvement in accuracy and class-specific metrics with Random Forest suggests that complex models are more suited for this particular task. Given the diverse and multi-dimensional nature of the data (various soil metrics influencing crop type), Random Forest can effectively capture the necessary interactions and non-linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b15d5",
   "metadata": {},
   "source": [
    "# B. Identify the Most Significant Variable\n",
    "\n",
    "This objective involves analyzing the feature importance to determine which soil metric is most predictive of the crop type. Here are the steps and the current status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1ef49a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "2    Potassium    0.334425\n",
      "1  Phosphorous    0.261151\n",
      "0     Nitrogen    0.206332\n",
      "3           pH    0.198092\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importances from the model\n",
    "importances = best_model.feature_importances_\n",
    "feature_names = ['Nitrogen', 'Phosphorous', 'Potassium', 'pH']\n",
    "\n",
    "# Create a DataFrame to view the importances\n",
    "importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(importances_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25323a",
   "metadata": {},
   "source": [
    "Here, Potassium has the highest importance score, indicating it was the most influential in determining the crop type according to the Random Forest model. Conversely, pH has the lowest score, suggesting it was the least influential of the four features in this specific context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f09a4",
   "metadata": {},
   "source": [
    "## Feature Importance in Random Forests: A Comprehensive Guide\n",
    "\n",
    "* In a Random Forest model, feature importance is calculated based on how much each feature reduces impurity in the data across all trees in the forest. Impurity measures how mixed the data is concerning the target variable at a particular node. Two common metrics for calculating impurity are:\n",
    "\n",
    "* Gini Impurity: Often used in classification tasks, Gini impurity measures the likelihood of an incorrect classification of a randomly chosen element. The lower the Gini impurity, the better the classification.\n",
    "\n",
    "* Information Gain: This metric calculates the difference in entropy from before and after a split on a feature, indicating the feature's contribution to reducing uncertainty in the target variable. The Random Forest model evaluates the reduction in impurity achieved by each feature across all decision trees. The feature that, on average, reduces impurity the most is considered the most important.\n",
    "\n",
    "### Why This Analysis Matters ?\n",
    "\n",
    "Understanding feature importance is crucial for several reasons:\n",
    "\n",
    "* Interpreting the Model: It helps in understanding what drives the model's predictions, providing insights into the underlying patterns in the farm data.\n",
    "\n",
    "* Feature Selection: Knowing the most important features can guide efforts to streamline the model or focus data collection on specific areas, thereby improving efficiency and effectiveness.\n",
    "\n",
    "* Practical Applications: In agriculture, identifying the most predictive soil metrics can inform soil management and fertilizer use, leading to more efficient and sustainable farming practices.\n",
    "\n",
    "### Interpreting the Importance Scores\n",
    "- Potassium (K): The highest importance score indicates that potassium levels are the most critical factor in predicting the crop type in your dataset. Potassium is crucial for various plant processes, including water regulation and nutrient transport, which are essential for crop health.\n",
    "\n",
    "- Phosphorous (P): The second most important feature, highlighting its significant role in energy transfer and photosynthesis, both of which are crucial for crop growth.\n",
    "\n",
    "- Nitrogen (N): The third in importance, emphasizing its role in promoting vegetative growth. Although crucial, nitrogen's impact is slightly less critical compared to potassium and phosphorous in this dataset.\n",
    "\n",
    "- pH: While still important, pH has the least influence among the four features. Soil pH significantly affects nutrient availability and uptake, which can impact different crops differently.\n",
    "\n",
    "### Why Random Forest is a Good Choice?\n",
    "\n",
    "Random Forest is an excellent choice for this type of analysis for several reasons:\n",
    "\n",
    "- Handles Multiclass Classification: It is inherently suited for multiclass classification problems, effectively managing the complexity of predicting multiple crop types.\n",
    "\n",
    "- Feature Importance: It provides natural feature importance metrics, guiding practical agricultural decisions like prioritizing soil tests for specific nutrients.\n",
    "\n",
    "- Non-Linear Relationships: The model captures non-linear relationships between features and the target variable, negating the need for feature scaling or transformations.\n",
    "\n",
    "- Robustness: Random Forest reduces the risk of overfitting and provides more stable predictions across different datasets.\n",
    "\n",
    "### Final Recommendations\n",
    "- Focus on High-Importance Features: Given the findings, potassium and phosphorous should be prioritized in soil management practices and testing. These nutrients are highly influential in crop prediction and should be closely monitored.\n",
    "\n",
    "- Regular Model Updating: As new data becomes available, particularly with changes in agricultural practices or crop varieties, the model should be regularly retrained to maintain its accuracy and relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abf318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
