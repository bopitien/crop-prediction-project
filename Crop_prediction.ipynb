{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5065db68",
   "metadata": {},
   "source": [
    "# Sowing Success: How Machine Learning Helps Farmers Select the Best Crops\n",
    "\n",
    "![Farmer in a field](farmer_in_a_field.jpg)\n",
    "\n",
    "Measuring essential soil metrics such as nitrogen, phosphorous, potassium levels, and pH value is an important aspect of assessing soil condition. However, it can be an expensive and time-consuming process, which can cause farmers to prioritize which metrics to measure based on their budget constraints.\n",
    "\n",
    "Farmers have various options when it comes to deciding which crop to plant each season. Their primary objective is to maximize the yield of their crops, taking into account different factors. One crucial factor that affects crop growth is the condition of the soil in the field, which can be assessed by measuring basic elements such as nitrogen and potassium levels. Each crop has an ideal soil condition that ensures optimal growth and maximum yield.\n",
    "\n",
    "A farmer reached out, as a machine learning expert for assistance in selecting the best crop for his field. They've provided a dataset called `soil_measures.csv`, which contains:\n",
    "\n",
    "- `\"N\"`: Nitrogen content ratio in the soil\n",
    "- `\"P\"`: Phosphorous content ratio in the soil\n",
    "- `\"K\"`: Potassium content ratio in the soil\n",
    "- `\"pH\"` value of the soil\n",
    "- `\"crop\"`: categorical values that contain various crops (target variable).\n",
    "\n",
    "Each row in this dataset represents various measures of the soil in a particular field. Based on these measurements, the crop specified in the `\"crop\"` column is the optimal choice for that field.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b375ae8e",
   "metadata": {},
   "source": [
    "### The task in this project involves two main objectives:\n",
    "\n",
    "1. Predict the Crop Type: Use the variables N (Nitrogen),P (Phosphorous), K (Potassium), and pH value of the soil to build a machine learning model that can predict the type of crop (categorical target variable) that would be best suited for a given set of soil conditions. This is a classic example of a multi-class classification problem.\n",
    "\n",
    "\n",
    "2. Identify the Most Significant Variable: Apart from predicting the crop type, a key part of the project is to determine which of these soil metrics (N, P, K, or pH) is the most predictive of the crop type. This involves analyzing the feature importance from the model to see which variable contributes the most to the model's predictive performance. This helps in understanding which soil metric is most critical for deciding the crop type, which can be very valuable for optimizing the use of resources in agricultural practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f904f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bd0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crops = pd.read_csv(\"soil_measures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40909f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>ph</th>\n",
       "      <th>crop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>7.073454</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>5.700806</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>5.718627</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>54</td>\n",
       "      <td>38</td>\n",
       "      <td>6.685346</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>58</td>\n",
       "      <td>38</td>\n",
       "      <td>6.336254</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N   P   K        ph  crop\n",
       "0  90  42  43  6.502985  rice\n",
       "1  85  58  41  7.038096  rice\n",
       "2  60  55  44  7.840207  rice\n",
       "3  74  35  40  6.980401  rice\n",
       "4  78  42  42  7.628473  rice\n",
       "5  69  37  42  7.073454  rice\n",
       "6  69  55  38  5.700806  rice\n",
       "7  94  53  40  5.718627  rice\n",
       "8  89  54  38  6.685346  rice\n",
       "9  68  58  38  6.336254  rice"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c079c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N         int64\n",
       "P         int64\n",
       "K         int64\n",
       "ph      float64\n",
       "crop     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612c97ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       0\n",
       "P       0\n",
       "K       0\n",
       "ph      0\n",
       "crop    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50961a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>ph</th>\n",
       "      <th>crop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.551818</td>\n",
       "      <td>53.362727</td>\n",
       "      <td>48.149091</td>\n",
       "      <td>6.469480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.917334</td>\n",
       "      <td>32.985883</td>\n",
       "      <td>50.647931</td>\n",
       "      <td>0.773938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.504752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.971693</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6.425045</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>84.250000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>6.923643</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>9.935091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  N            P            K           ph  crop\n",
       "count   2200.000000  2200.000000  2200.000000  2200.000000  2200\n",
       "unique          NaN          NaN          NaN          NaN    22\n",
       "top             NaN          NaN          NaN          NaN  rice\n",
       "freq            NaN          NaN          NaN          NaN   100\n",
       "mean      50.551818    53.362727    48.149091     6.469480   NaN\n",
       "std       36.917334    32.985883    50.647931     0.773938   NaN\n",
       "min        0.000000     5.000000     5.000000     3.504752   NaN\n",
       "25%       21.000000    28.000000    20.000000     5.971693   NaN\n",
       "50%       37.000000    51.000000    32.000000     6.425045   NaN\n",
       "75%       84.250000    68.000000    49.000000     6.923643   NaN\n",
       "max      140.000000   145.000000   205.000000     9.935091   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7505c6ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rice', 'maize', 'chickpea', 'kidneybeans', 'pigeonpeas',\n",
       "       'mothbeans', 'mungbean', 'blackgram', 'lentil', 'pomegranate',\n",
       "       'banana', 'mango', 'grapes', 'watermelon', 'muskmelon', 'apple',\n",
       "       'orange', 'papaya', 'coconut', 'cotton', 'jute', 'coffee'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops[\"crop\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf7aec",
   "metadata": {},
   "source": [
    "# A. Predict the Crop Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf1f45",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67729f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = crops[['N', 'P', 'K', 'ph']] \n",
    "y = crops['crop']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the training data and transform the test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f566ee7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b11c51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6590909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.88      0.30      0.45        23\n",
      "      banana       1.00      1.00      1.00        21\n",
      "   blackgram       0.76      0.65      0.70        20\n",
      "    chickpea       1.00      0.77      0.87        26\n",
      "     coconut       0.81      0.63      0.71        27\n",
      "      coffee       0.76      0.76      0.76        17\n",
      "      cotton       0.88      0.88      0.88        17\n",
      "      grapes       0.45      0.93      0.60        14\n",
      "        jute       0.50      0.48      0.49        23\n",
      " kidneybeans       0.45      0.65      0.53        20\n",
      "      lentil       0.30      0.64      0.41        11\n",
      "       maize       0.91      1.00      0.95        21\n",
      "       mango       0.40      0.53      0.45        19\n",
      "   mothbeans       0.60      0.25      0.35        24\n",
      "    mungbean       0.67      0.74      0.70        19\n",
      "   muskmelon       0.62      0.76      0.68        17\n",
      "      orange       1.00      1.00      1.00        14\n",
      "      papaya       0.74      1.00      0.85        23\n",
      "  pigeonpeas       0.18      0.09      0.12        23\n",
      " pomegranate       0.69      0.87      0.77        23\n",
      "        rice       0.38      0.32      0.34        19\n",
      "  watermelon       0.73      0.58      0.65        19\n",
      "\n",
      "    accuracy                           0.66       440\n",
      "   macro avg       0.67      0.67      0.65       440\n",
      "weighted avg       0.68      0.66      0.65       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict the crop types on the scaled test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49834d",
   "metadata": {},
   "source": [
    "### Implementation Steps:\n",
    "* Data Preparation: Features and labels are defined, data is split into training and testing sets.\n",
    "\n",
    "* Feature Scaling: StandardScaler is used to scale the features, which is crucial for logistic regression as it relies on gradient descent algorithms that benefit from feature scaling.\n",
    "\n",
    "* Model Training and Prediction: A logistic regression model is initialized and trained on the scaled data. Predictions are then made on the test set.\n",
    "\n",
    "* Evaluation: The model's performance is assessed using accuracy and a detailed classification report which provides precision, recall, and F1-scores for each class.\n",
    "\n",
    "### Outcomes:\n",
    "* Overall Accuracy: 65.91%, indicating that the model correctly predicts the crop type for about two-thirds of the test set but rom for improbememt.\n",
    "\n",
    "* Performance Variability: The model performs well for certain crops like banana and chickpea but struggles with others like pigeonpeas and rice, suggesting variability in its ability to handle different classes, again the need for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b59371",
   "metadata": {},
   "source": [
    "## 2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2975afa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Accuracy: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       0.76      0.70      0.73        23\n",
      "      banana       1.00      1.00      1.00        21\n",
      "   blackgram       0.86      0.90      0.88        20\n",
      "    chickpea       1.00      1.00      1.00        26\n",
      "     coconut       0.84      1.00      0.92        27\n",
      "      coffee       0.94      0.94      0.94        17\n",
      "      cotton       0.89      1.00      0.94        17\n",
      "      grapes       0.56      0.64      0.60        14\n",
      "        jute       0.56      0.83      0.67        23\n",
      " kidneybeans       0.77      1.00      0.87        20\n",
      "      lentil       0.50      0.73      0.59        11\n",
      "       maize       1.00      0.95      0.98        21\n",
      "       mango       1.00      0.74      0.85        19\n",
      "   mothbeans       0.95      0.83      0.89        24\n",
      "    mungbean       0.79      1.00      0.88        19\n",
      "   muskmelon       0.59      0.59      0.59        17\n",
      "      orange       1.00      1.00      1.00        14\n",
      "      papaya       1.00      1.00      1.00        23\n",
      "  pigeonpeas       0.82      0.39      0.53        23\n",
      " pomegranate       1.00      0.91      0.95        23\n",
      "        rice       0.57      0.21      0.31        19\n",
      "  watermelon       0.63      0.63      0.63        19\n",
      "\n",
      "    accuracy                           0.82       440\n",
      "   macro avg       0.82      0.82      0.81       440\n",
      "weighted avg       0.83      0.82      0.82       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "\n",
    "\n",
    "crops = pd.read_csv('soil_measures.csv')\n",
    "\n",
    "# Ensure ph is treated as float\n",
    "crops['ph'] = crops['ph'].astype(float)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "crops['crop'] = label_encoder.fit_transform(crops['crop'])\n",
    "\n",
    "# Define features and target\n",
    "X = crops[['N', 'P', 'K', 'ph']]\n",
    "y = crops['crop']\n",
    "\n",
    "# Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Define the model with class weights\n",
    "rf = RandomForestClassifier(random_state=42, class_weight=class_weights_dict)\n",
    "\n",
    "# Set up hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, \n",
    "                           n_jobs=-1, verbose=2, scoring='f1_macro')\n",
    "\n",
    "# Fit grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Decode the predictions back to original class labels\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test_decoded, y_pred_decoded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee9085",
   "metadata": {},
   "source": [
    "### Implementation Steps:\n",
    "\n",
    "* Model Setup: Random Forest Classifier is defined.\n",
    "\n",
    "\n",
    "* Hyperparameter Tuning: GridSearchCV is utilized to find the optimal parameters (like the number of trees, maximum depth of trees, etc.) across a specified grid. This helps in optimizing the model by tuning it to the best possible configuration for the given data.\n",
    "\n",
    "\n",
    "* Model Training and Prediction: The best model from GridSearchCV is used to make predictions on the test set.\n",
    "\n",
    "\n",
    "* Evaluation: Similar to logistic regression, the modelâ€™s performance is evaluated using accuracy and a detailed classification report.\n",
    "\n",
    "### Outcomes:\n",
    "* Overall Accuracy: 82.5%, a significant improvement over the logistic regression model.\n",
    "\n",
    "* Enhanced Performance: The Random Forest model shows not only higher overall accuracy but also improved precision, recall, and F1-scores for most crops. This indicates a better handling of class variability and an overall stronger predictive performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b795798",
   "metadata": {},
   "source": [
    "### Rationale Behind this model Selection\n",
    "* Logistic Regression: A good baseline model for binary classification tasks. It's relatively simple and interpretable but may not handle complex relationships and interactions between features as effectively, especially in multi-class settings.\n",
    "\n",
    "* Random Forest: An ensemble method that builds multiple decision trees and aggregates their predictions. It's more robust against overfitting and can capture complex patterns in the data, making it suitable for tasks with high-dimensional feature space and multiple classes.\n",
    "\n",
    "\n",
    "The significant improvement in accuracy and class-specific metrics with Random Forest suggests that complex models are more suited for this particular task. Given the diverse and multi-dimensional nature of the data (various soil metrics influencing crop type), Random Forest can effectively capture the necessary interactions and non-linear relationships compared to binary class model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e286178",
   "metadata": {},
   "source": [
    "# B. Identify the Most Significant Variable\n",
    "\n",
    "This objective involves analyzing the feature importance to determine which soil metric is most predictive of the crop type. Here are the steps and the current status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de0f383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "2    Potassium    0.347810\n",
      "1  Phosphorous    0.257595\n",
      "0     Nitrogen    0.205841\n",
      "3           pH    0.188754\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importances\n",
    "importances = best_model.feature_importances_\n",
    "feature_names = ['Nitrogen', 'Phosphorous', 'Potassium', 'pH']\n",
    "\n",
    "# Create a DataFrame to view the importances\n",
    "importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}\n",
    "                             ).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "\n",
    "print(importances_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a42895",
   "metadata": {},
   "source": [
    "Here, Potassium has the highest importance score, indicating it was the most influential in determining the crop type according to the Random Forest model. Conversely, pH has the lowest score, suggesting it was the least influential of the four features in this specific context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d3c42",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f474ac34",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Why This Analysis Matters ?\n",
    "\n",
    "Understanding feature importance is crucial for several reasons:\n",
    "\n",
    "* Interpreting the Model: It helps in understanding what drives the model's predictions, providing insights into the underlying patterns in the farm data.\n",
    "\n",
    "* Feature Selection: Knowing the most important features can guide efforts to streamline the model or focus data collection on specific areas, thereby improving efficiency and effectiveness.\n",
    "\n",
    "* Practical Applications: In agriculture, identifying the most predictive soil metrics can inform soil management and fertilizer use, leading to more efficient and sustainable farming practices.\n",
    "\n",
    "\n",
    "### Why Random Forest is a Good Choice?\n",
    "\n",
    "Random Forest is an excellent choice for this type of analysis for several reasons:\n",
    "\n",
    "- Handles Multiclass Classification: It is inherently suited for multiclass classification problems, effectively managing the complexity of predicting multiple crop types.\n",
    "\n",
    "- Feature Importance: It provides natural feature importance metrics, guiding practical agricultural decisions like prioritizing soil tests for specific nutrients.\n",
    "\n",
    "- Non-Linear Relationships: The model captures non-linear relationships between features and the target variable, negating the need for feature scaling or transformations.\n",
    "\n",
    "- Robustness: Random Forest reduces the risk of overfitting and provides more stable predictions across different datasets.\n",
    "\n",
    "### Final Recommendations\n",
    "\n",
    "- Focus on High-Importance Features: Given the findings, potassium and phosphorous should be prioritized in soil management practices and testing. These nutrients are highly influential in crop prediction and should be closely monitored.\n",
    "\n",
    "- Regular Model Updating: As new data becomes available, particularly with changes in agricultural practices or crop varieties, the model should be regularly retrained to maintain its accuracy and relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5f8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0311a705",
   "metadata": {},
   "source": [
    "## Model Export and Serialization with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28080192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save the model and the label encoder\n",
    "joblib.dump(best_model, 'random_forest_model.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a36d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
